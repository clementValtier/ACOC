# ACOC - Adaptive Controlled Organic Capacity

Architecture de r√©seau neuronal √† croissance dynamique avec expansion contr√¥l√©e, routage intelligent et support multi-modal (Images/Texte/Audio).

## üéØ Concept

ACOC est un mod√®le d'IA qui d√©marre avec une architecture minimale et s'agrandit progressivement selon ses besoins r√©els, √©vitant le sur-dimensionnement tout en maintenant la capacit√© d'apprentissage. Le syst√®me d√©tecte automatiquement le type de donn√©es (images, texte, audio) et utilise l'architecture appropri√©e (CNN/MLP).

### ‚ú® Principes Cl√©s

- **Croissance Organique** : Le mod√®le commence petit et ajoute des neurones/couches uniquement quand n√©cessaire
- **D√©tection Automatique** : Reconna√Æt images/texte/audio et applique un biais l√©ger vers l'architecture adapt√©e
- **Support Multi-Modal** : CNN automatiques pour images, MLP pour texte/audio, avec routeur intelligent
- **Double Malus** : P√©nalit√© globale (logarithmique) + p√©nalit√© par t√¢che (quadratique) pour forcer la parcimonie
- **Vote par Consensus** : 5 variantes l√©g√®res (deltas) votent sur les d√©cisions d'expansion avec seuil adaptatif
- **Protection Anti-Forgetting** : EWC sur le routeur + isolation des blocs de t√¢ches

## üìä R√©sultats

| Dataset | Type | Accuracy | CNN/MLP | Expansions |
|---------|------|----------|---------|------------|
| **MNIST** | Images 28√ó28 | **~98%+** | CNN 100% | 0 |
| **Fashion-MNIST** | Images 28√ó28 | **91.15%** | CNN 100% | 0 |
| **CIFAR-10** | Images 32√ó32√ó3 | **75.38%** | CNN 82% | 0 |
| **CIFAR-100** | Images 32√ó32√ó3 | **~45-50%** | CNN 90%+ | 0-2 |
| **IMDB** | Texte (sentiment) | **~85%+** | MLP 100% | 0-2 |
| **Speech Commands** | Audio | **~85%+** | MLP 100% | 0-2 |

Le syst√®me converge de mani√®re stable sans expansions inutiles, en utilisant l'architecture appropri√©e automatiquement.

## üöÄ Installation

```bash
# Cloner le repository
git clone https://github.com/clementValtier/ACOC.git
cd acoc

# Cr√©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate  # ou `venv\Scripts\activate` sur Windows

# Installer les d√©pendances de base
pip install -r requirements.txt

# Installer en mode d√©veloppement
pip install -e .

# Pour le support texte (IMDB)
pip install datasets transformers

# Pour le support audio (Speech Commands)
pip install torchaudio
```

## üéÆ Quick Start

### Images (MNIST - Chiffres)
```bash
python3 scripts/train_mnist.py
```

### Images (Fashion-MNIST - V√™tements)
```bash
python3 scripts/train_fashion.py
```

### Images (CIFAR-10 - 10 classes)
```bash
python3 scripts/train_cifar10.py
```

### Images (CIFAR-100 - 100 classes)
```bash
python3 scripts/train_cifar100.py
```

### Texte (IMDB Sentiment Analysis)
```bash
python3 scripts/train_imdb.py
```

### Audio (Speech Commands)
```bash
python3 scripts/train_speech_commands.py
```

## üìñ Usage Avanc√©

```python
from acoc import ACOCModel, ACOCTrainer, SystemConfig

# Configuration
config = SystemConfig(
    device='cuda',
    input_dim=3072,      # 32√ó32√ó3 pour CIFAR-10
    hidden_dim=512,
    output_dim=10,
    use_cnn=True,        # Active les CNN pour images
    saturation_threshold=0.8,
    min_cycles_before_expand=10,
    expansion_cooldown=15
)

# Cr√©ation du mod√®le
model = ACOCModel(config)

# Le routeur d√©tecte automatiquement le type de donn√©es et applique un biais l√©ger
# vers l'architecture appropri√©e (CNN pour images, MLP pour texte/audio)

# Entra√Ænement
trainer = ACOCTrainer(model, config, class_names=['class1', 'class2'])
trainer.train(
    train_loader=train_loader,
    test_loader=test_loader,
    num_cycles=50,
    save_path='model.pth'
)
```

## üèóÔ∏è Architecture

### Structure du Projet

```
acoc/
‚îú‚îÄ‚îÄ config/          # Configuration et structures de donn√©es
‚îú‚îÄ‚îÄ core/            # Router avec d√©tection automatique du type de donn√©es
‚îú‚îÄ‚îÄ experts/         # BaseExpert, MLPExpert, CNNExpert, ExpertFactory
‚îú‚îÄ‚îÄ monitoring/      # Monitoring des gradients et activations
‚îú‚îÄ‚îÄ management/      # Expansion, Warmup, Penalty, Pruning
‚îú‚îÄ‚îÄ variants/        # Syst√®me de vote par variantes
‚îú‚îÄ‚îÄ model/           # Mod√®le ACOC principal avec routage intelligent
‚îú‚îÄ‚îÄ training/        # Boucle d'entra√Ænement
‚îî‚îÄ‚îÄ scripts/         # Scripts de training pour diff√©rents datasets
```

### Architecture Modulaire avec Factory Pattern

```python
# Syst√®me d'experts modulaire
BaseExpert (classe abstraite)
‚îú‚îÄ‚îÄ MLPExpert        # Pour texte et audio
‚îî‚îÄ‚îÄ CNNExpert        # Pour images avec d√©tection auto des dimensions

# Factory pour cr√©er automatiquement le bon type d'expert
expert = ExpertFactory.create(
    expert_type="cnn",  # ou "mlp"
    input_dim=3072,
    config=config
)
```

### D√©tection Automatique du Type de Donn√©es

Le routeur d√©tecte automatiquement le type de donn√©es en analysant :

1. **Dimension** : Si `input_dim` forme un carr√© parfait (784=28¬≤, 3072=32¬≤√ó3) ‚Üí **Image**
2. **Statistiques** : Distribution, variance, plage de valeurs ‚Üí **Texte/Audio**

Un biais l√©ger (+1.0 √† +2.0) est appliqu√© vers l'architecture appropri√©e, laissant le routeur apprendre naturellement :

```python
# D√©tection automatique au premier forward
data_type = router.detect_data_type(x)  # "image", "text", ou "audio"

# Biais l√©ger vers l'architecture appropri√©e
if data_type == "image":
    router.set_route_bias(base_image_idx, 2.0)  # Oriente vers CNN
```

## üîÑ Boucle d'Entra√Ænement

1. **TRAINING** : Architecture fixe, backpropagation normale (5 min par cycle)
2. **CHECKPOINT** : √âvaluation + vote des 5 variantes (seuil relatif √† l'historique)
3. **D√âCISION** : Analyse des m√©triques de saturation (gradient flow, activations, neurones morts)
4. **EXPANSION** : Modification de l'architecture si n√©cessaire (width/depth/new_block)
5. **WARMUP** : LR √ó 5 pour nouveaux param√®tres + exploration forc√©e (10%)
6. **MAINTENANCE** : Pruning des blocs inutilis√©s + consolidation des blocs similaires

## üìà M√©triques de Saturation

Le syst√®me combine 4 m√©triques pour d√©tecter le besoin d'expansion :

- **Gradient Flow Ratio** : Proportion de gradients "vivants" (> seuil)
- **Activation Saturation** : Ratio de neurones satur√©s (> 95% du max)
- **Dead Neuron Ratio** : Ratio de neurones toujours √† 0
- **Activation Variance** : Diversit√© des activations inter-batch

Score combin√© pond√©r√© : `0.35√ógradient + 0.25√ósaturation + 0.20√ódead + 0.20√óvariance`

## üîß Expansion

### Types d'Expansion

- **Width** : Ajout de neurones (Net2Net avec duplication + bruit)
- **Depth** : Ajout de couches
- **New Block** : Cr√©ation d'un nouveau bloc de t√¢che

### D√©clencheurs (Param√®tres Recommand√©s)

- Score de saturation combin√© > **80%** (configurable, augment√© pour stabilit√©)
- Minimum **10 cycles** avant premi√®re expansion (patience accrue)
- **15 cycles** de cooldown entre expansions (stabilit√©)
- Loss stagnante (< 1% d'am√©lioration sur 10 cycles)
- Vote majoritaire des variantes (consensus)

### Stabilisation Post-Expansion

- Learning rate multipli√© (√ó5) pour nouveaux param√®tres
- Exploration forc√©e vers nouveaux blocs (10% de probabilit√©)
- P√©riode de warmup configurable (50 steps par d√©faut)

## üí∞ Double Malus

```python
Loss_total = Loss_task
           + Œ± √ó log(1 + params_global / params_baseline)
           + Œ≤ √ó Œ£ max(0, params_task_i - threshold_i)¬≤
```

- **Œ± = 0.01** : P√©nalit√© globale (logarithmique)
- **Œ≤ = 0.05** : P√©nalit√© par t√¢che (quadratique au-del√† du seuil)

Le malus s'adapte automatiquement : se rel√¢che si la loss stagne, se resserre si am√©lioration rapide.

## üé≤ Syst√®me de Variantes

5 variantes l√©g√®res du m√™me mod√®le (deltas) pour explorer l'espace des poids :

```python
model_base = load_model()                    # 1 mod√®le en m√©moire
deltas = [small_perturbation() for _ in 5]  # 5 petits deltas

# Vote avec seuil relatif
threshold = 0.95 √ó mean(last_5_scores)
votes = [evaluate(model + delta) < threshold for delta in deltas]
should_expand = majority(votes)
```

Co√ªt m√©moire minimal : les deltas sont ~0.1% de la taille du mod√®le.

## üß† Catastrophic Forgetting

### Mitigation Architecturale

- Blocs de t√¢ches s√©par√©s (isolation naturelle)
- Malus par t√¢che (emp√™che l'invasion)
- Ajout plut√¥t que modification (Progressive Networks style)

### Protection du Routeur

- **EWC (Elastic Weight Consolidation)** sur le routeur central
- Fisher Information Matrix calcul√©e p√©riodiquement
- P√©nalit√© sur les changements des poids critiques

### Maintenance

- **Pruning** : Suppression des blocs inutilis√©s (< 10% utilisation apr√®s 20 cycles)
- **Consolidation** : Fusion de blocs similaires (similarit√© > 90%)

## ‚öôÔ∏è Configuration

### Hyperparam√®tres Principaux (Valeurs Recommand√©es 2026)

```python
SystemConfig(
    # Architecture
    input_dim=3072,              # D√©pend du dataset
    hidden_dim=512,
    output_dim=10,

    # CNN (pour images)
    use_cnn=True,
    cnn_channels=[32, 64, 128],  # Structure CNN
    image_channels=3,            # 3 pour RGB, 1 pour grayscale

    # Expansion (valeurs plus conservatrices pour stabilit√©)
    saturation_threshold=0.8,         # 80% au lieu de 60%
    min_cycles_before_expand=10,      # 10 au lieu de 3
    expansion_cooldown=15,            # 15 au lieu de 5
    expansion_ratio=0.1,              # Ajouter 10% de neurones
    recent_usage_window=5,            # Fen√™tre pour utilisation

    # P√©nalit√©s
    alpha_global_penalty=0.01,        # P√©nalit√© globale
    beta_task_penalty=0.05,           # P√©nalit√© par t√¢che
    task_param_threshold=1_000_000,   # Seuil avant p√©nalit√©

    # Variantes
    num_variants=5,                   # 5 variantes pour le vote
    delta_magnitude=0.01,             # Amplitude des perturbations
    performance_threshold_ratio=0.95, # Seuil relatif (95% moyenne)

    # Warmup
    warmup_steps=50,                  # Steps de warmup
    warmup_lr_multiplier=5.0,         # LR √ó 5 pour nouveaux params
    new_block_exploration_prob=0.1,   # 10% exploration (r√©duit)
    new_block_exploration_cycles=3,   # Cycles d'exploration
    max_warmup_cycles=10,             # Cycles max avant d√©sactivation

    # Maintenance
    prune_unused_after_cycles=20,
    consolidation_similarity_threshold=0.9,
    maintenance_interval=5,

    # Device
    device='cuda'  # 'cuda', 'mps', ou 'cpu'
)
```

## üìù Ajouter un Nouveau Dataset

Tous les scripts de training utilisent `BaseACOCTrainer` pour factoriser le code commun. Pour ajouter un dataset :

```python
from scripts.base_trainer import BaseACOCTrainer
from acoc import SystemConfig

class MyTrainer(BaseACOCTrainer):
    CLASSES = ['ClasseA', 'ClasseB']

    def get_config(self):
        return SystemConfig(
            device=self.device,
            input_dim=1000,
            output_dim=2,
            use_cnn=False  # True pour images
        )

    def get_dataloaders(self):
        # Charger et retourner (train_loader, test_loader)
        return train_loader, test_loader

    def get_class_names(self):
        return self.CLASSES

    def get_dataset_name(self):
        return "my_dataset"

    def get_dataset_info(self):
        return {"Input": 1000, "Classes": "A, B"}

if __name__ == '__main__':
    trainer = MyTrainer(num_cycles=50)
    trainer.run()
```

Voir `scripts/README.md` pour plus de d√©tails.

## üß™ Tests

```bash
# Tests unitaires
pytest tests/

# Test sp√©cifique
pytest tests/test_expansion.py -v
```

## üìö R√©f√©rences

### Concepts Utilis√©s

- **NEAT** (Stanley, 2002) : Neuro√©volution avec topologie augment√©e
- **Net2Net** (Chen et al., 2015) : Expansion de r√©seaux pr√©servant la fonction
- **LEMON** (ICLR 2024) : Expansion lossless pour Transformers
- **Mixture of Experts** : GPT-4, Mixtral, DeepSeek-V3
- **Model Soups** (2022) : Moyennage de poids sans co√ªt d'inf√©rence
- **Progressive Neural Networks** (DeepMind) : Anti-forgetting par ajout de colonnes
- **EWC** (Kirkpatrick et al., 2017) : Elastic Weight Consolidation

### √âtat de l'Art

- **DynMoE** (ICLR 2025) : Ajustement dynamique du nombre d'experts
- **Growth-based NAS** : Construction layer-by-layer
- **Continual Learning** : CoMA/CoFiMA avec Fisher information
- **Multimodal Unified Models** (2024-2025) : GPT-4o, Gemini

## üéØ Roadmap

- [x] Support CNN automatique pour images
- [x] D√©tection automatique du type de donn√©es
- [x] Factory pattern pour experts modulaires
- [x] Scripts de training refactoris√©s
- [x] Support multi-modal (Images/Texte/Audio)
- [ ] Support GPU multi-GPU (DataParallel/DistributedDataParallel)
- [ ] Benchmark vs baselines (MoE statique, Progressive Networks)
- [ ] M√©canisme de partage inter-branches
- [ ] Support pour transformers et attention

## üìÑ Licence

MIT

## üë• Contact

ACOC Project - v0.3.0 (2026)

Auteur : Cl√©ment Valtier
